{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Apply Graph Analytics\n",
    "\n",
    "This module has the following objectives:\n",
    "1. Deduplicating definitions that are very similar\n",
    "2. Use GDS to find useful patterns in the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import our usual suspects (and some more...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import Query, GraphDatabase, RoutingControl, Result\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file = 'ws.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(env_file):\n",
    "    load_dotenv(env_file, override=True)\n",
    "\n",
    "    # Neo4j\n",
    "    HOST = os.getenv('NEO4J_URI')\n",
    "    USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "    PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "    DATABASE = os.getenv('NEO4J_DATABASE')\n",
    "else:\n",
    "    print(f\"File {env_file} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup connection to the database with the [Python Driver](https://neo4j.com/docs/python-manual/5/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "    HOST,\n",
    "    auth=(USERNAME, PASSWORD)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to split large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, chunk_size = 50_000):\n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (n) RETURN COUNT(n) as Count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracted Definitions\n",
    "\n",
    "In Notebook 1, we saw that some definitions are **very similar** to each other or are **occurring in many documents and chunks**. Let's analyse this and see if we can find solutions to deal with these points!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder notebook 1: what definitions are mentioned most frequently within chunks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_count_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (doc:Document)<-[:PART_OF]-(chunk:Chunk)-[:MENTIONS]->(def:Definition)\n",
    "    WITH DISTINCT def, COUNT(DISTINCT chunk) AS chunk_count, COUNT(DISTINCT doc) AS document_count\n",
    "    RETURN def.term AS definition, def.description AS description, chunk_count, document_count ORDER BY chunk_count DESC LIMIT 25\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplicate definitions\n",
    "\n",
    "As you can see, there are many similar/duplicate definitions that we would ideally merge together. That's what we'll try in this section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar definitions based on [Levenshtein](https://neo4j.com/labs/apoc/4.1/overview/apoc.text/apoc.text.distance/) distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein_definitions_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (a:Definition), (b:Definition)\n",
    "    WHERE elementId(a) < elementId(b) AND apoc.text.distance(toLower(a.term), toLower(b.term)) < 3\n",
    "    RETURN a.term, b.term\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein_definitions_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use embeddings\n",
    "\n",
    "Levenshtein distance is not always ideal, as sometimes completely different terms have small edit distance. \n",
    "\n",
    "Let's see if embeddings do a better job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_result_df  = driver.execute_query(\n",
    "    'SHOW INDEXES',\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")\n",
    "schema_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return similar definitions based on embeddings distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_definitions_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (n:Definition)\n",
    "    CALL db.index.vector.queryNodes('definition-embeddings', 10, n.embedding)\n",
    "    YIELD node AS similar, score\n",
    "    WHERE elementId(n) < elementId(similar)\n",
    "    \n",
    "    //Make sure that the definitions are from the same document\n",
    "    MATCH (n)<-[:MENTIONS]-(chunk:Chunk)-[:PART_OF]->(source_doc:Document)\n",
    "    MATCH (similar)<-[:MENTIONS]-(chunk:Chunk)-[:PART_OF]->(target_doc:Document)\n",
    "    RETURN DISTINCT n.term AS source, similar.term AS target, apoc.coll.sort(COLLECT(source_doc.file_name)) AS source_files, apoc.coll.sort(COLLECT(target_doc.file_name)) AS target_files, score\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_definitions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_definitions_df.loc[(similar_definitions_df[\"score\"] > 0.97) & (similar_definitions_df[\"source_files\"] == similar_definitions_df[\"target_files\"])].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_terms = similar_definitions_df.loc[(similar_definitions_df[\"score\"] > 0.97) & (similar_definitions_df[\"source_files\"] == similar_definitions_df[\"target_files\"])]\n",
    "len(similar_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of relations between `Chunk` and `Definition` before deduplicating defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "        MATCH p=()-[r:MENTIONS]->() RETURN COUNT(r) as count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `Definitions` before deduplicating defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "        MATCH (n:Definition) RETURN COUNT(n) as count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge nodes with similar embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in similar_terms.iterrows():\n",
    "    driver.execute_query(\n",
    "        \"\"\"\n",
    "        MATCH (a:Definition {term: $source}), (b:Definition {term: $target})\n",
    "        CALL apoc.refactor.mergeNodes([a, b], {\n",
    "            properties: \"overwrite\",\n",
    "            mergeRels: true\n",
    "        })\n",
    "        YIELD node\n",
    "        RETURN node\n",
    "        \"\"\",\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        result_transformer_= lambda r: r.to_df(),\n",
    "        source=row['source'],\n",
    "        target=row['target']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of relations between `Chunk` and `Definition` after deduplicating defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "        MATCH p=()-[r:MENTIONS]->() RETURN COUNT(r) as count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `Definitions` after deduplicating defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "        MATCH (n:Definition) RETURN COUNT(n) as count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look once again at the most occurring definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_count_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (doc:Document)<-[:PART_OF]-(chunk:Chunk)-[:MENTIONS]->(def:Definition)\n",
    "    WITH DISTINCT def, COUNT(DISTINCT chunk) AS chunk_count, COUNT(DISTINCT doc) AS document_count\n",
    "    RETURN def.term AS definition, def.description AS description, chunk_count, document_count ORDER BY chunk_count DESC LIMIT 25\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the Definition graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many definitions did we extract on average from Chunks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions_per_chunk_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (doc:Document)<-[:PART_OF]-(chunk:Chunk)-[:MENTIONS]->(def:Definition)\n",
    "    WITH DISTINCT doc, chunk, COUNT(def) AS definition_count\n",
    "    RETURN doc.file_name AS file_name, AVG(definition_count) AS avg_definitions_per_chunk_count, MIN(definition_count) AS min_definitions_per_chunk_count, MAX(definition_count) AS max_definitions_per_chunk_count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions_per_chunk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many shared definitions do documents have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_name = \"Payment and Online Services Terms Sept 2022.pdf\"  \n",
    "\n",
    "shared_definitions_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (doc1:Document {file_name: $doc_name})<-[:PART_OF]-(:Chunk)-[:MENTIONS]->(def:Definition)<-[:MENTIONS]-(:Chunk)-[:PART_OF]->(doc2:Document)\n",
    "    WHERE doc1 <> doc2\n",
    "    WITH DISTINCT doc1, doc2, COLLECT(DISTINCT def) AS definitions\n",
    "    RETURN doc1.file_name AS file_name_1, doc2.file_name AS file_name_2, SIZE(definitions) AS shared_definitions_count ORDER BY shared_definitions_count DESC\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df(),\n",
    "    doc_name=doc_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_definitions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk Similarity\n",
    "\n",
    "Definitions can be informative about the content of chunks and can for example be used to see which chunks are **similar**\n",
    "\n",
    "We can define the similarity of chunks based on **overlapping definitions**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start by setting the degree property on `Definition` nodes. Definitions occurring in many chunks are less informative, so we can use this property to filter those out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set property\n",
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (chunk:Chunk)-[:MENTIONS]->(def:Definition)\n",
    "    WITH DISTINCT def, COUNT(chunk) AS chunk_count\n",
    "    SET def.degree = chunk_count\n",
    "    RETURN COUNT(*) AS rows_processed\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we find similar chunks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 30  # Used to filter out frequently occurring definitions\n",
    "\n",
    "similar_chunks_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (chunk_1:Chunk)-[:MENTIONS]->(def:Definition)<-[:MENTIONS]-(chunk_2:Chunk)\n",
    "    WHERE chunk_1 > chunk_2 AND def.degree <= $threshold\n",
    "    WITH DISTINCT chunk_1, chunk_2, COLLECT(DISTINCT def.term) AS definitions, COUNT(DISTINCT def) AS definition_count\n",
    "    WHERE definition_count > 1\n",
    "    RETURN chunk_1.id AS chunk_1_id ,chunk_1.chunk_eng AS chunk_1, chunk_2.id AS chunk_2_id, chunk_2.chunk_eng AS chunk_2, definitions, definition_count ORDER BY definition_count DESC\n",
    "\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df(),\n",
    "    threshold=threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(similar_chunks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_chunks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the overlapping definition count to the database as **new relationship**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in split_dataframe(similar_chunks_df):\n",
    "    records, summary, keys = driver.execute_query(\n",
    "        \"\"\"\n",
    "        UNWIND $rows AS row\n",
    "        MERGE (p1:Chunk {id:row.chunk_1_id})\n",
    "        MERGE (p2:Chunk {id:row.chunk_2_id})\n",
    "        MERGE (p1)-[s:OVERLAPPING_DEFINITIONS]->(p2)\n",
    "        SET s.overlap = row.definition_count\n",
    "        RETURN COUNT(*) AS rows_processed\n",
    "        \"\"\",\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        rows = chunk.to_dict('records')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute to explore the `OVERLAPPING_DEFINITIONS` network in the database\n",
    "\n",
    "- `MATCH p=()-[:OVERLAPPING_DEFINITIONS]->() RETURN p LIMIT 50`\n",
    "\n",
    "- `MATCH p=()-[r:OVERLAPPING_DEFINITIONS]->() WHERE r.overlap >= 5 RETURN p LIMIT 50`\n",
    "\n",
    "- `MATCH p=()-[r:OVERLAPPING_DEFINITIONS]->() WHERE r.overlap >= 10 RETURN p LIMIT 50`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communities\n",
    "\n",
    "Let's run some Graph Data Science based on Chunks and Definitions. Let's first setup the [Graph Data Science Client](https://neo4j.com/docs/graph-data-science-client/current/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds = GraphDataScience.from_neo4j_driver(driver=driver)\n",
    "gds.set_database(DATABASE)\n",
    "gds.version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the Chunks that are similar in the graph (based on the definitions they share). For that we first need to create a [Graph object](https://neo4j.com/docs/graph-data-science-client/current/graph-object/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_name = \"chunk_similarity_projection\"\n",
    "node_projection = [\"Chunk\"]\n",
    "rel_projection = {\"OVERLAPPING_DEFINITIONS\": {\"orientation\": 'UNDIRECTED', \"properties\": \"overlap\"}, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, res = gds.graph.project(graph_name, node_projection, rel_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.graph.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the [Leiden Algorithm](https://neo4j.com/docs/graph-data-science/current/algorithms/leiden/) for Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.leiden.write(\n",
    "    G,\n",
    "    writeProperty='leiden_community',\n",
    "    relationshipWeightProperty='overlap',\n",
    "    maxLevels=100,\n",
    "    gamma=3,\n",
    "    theta=0.0001,\n",
    "    concurrency = 1,\n",
    "    randomSeed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (c:Chunk)\n",
    "    RETURN c.leiden_community AS community, COUNT(*) as member_count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_df.sort_values(by='member_count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(communities_df.loc[lambda df: df['member_count'] > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check communities based on Chunks with high overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_check_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (c1:Chunk)-[s:OVERLAPPING_DEFINITIONS]->(c2:Chunk)\n",
    "    WHERE s.overlap > 5\n",
    "    RETURN s.overlap AS overlap, c1.chunk_eng AS chunk_1, c1.leiden_community AS community_1, c2.chunk_eng AS chunk_2, c2.leiden_community AS community_2 ORDER BY s.overlap DESC\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_check_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some high definition occurrences in the communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_definitions_df = gds.run_cypher('''\n",
    "    MATCH (c:Chunk)-[:MENTIONS]->(def:Definition) WHERE (c.leiden_community) IS NOT NULL AND def.degree <= 30\n",
    "    WITH c.leiden_community AS leiden_community, def.term as definition, count(*) as cnt\n",
    "    WHERE cnt > 7\n",
    "    RETURN *\n",
    "    ORDER BY leiden_community, cnt DESC\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_definitions_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Communities with their Definition count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = gds.run_cypher(\"\"\"\n",
    "MATCH (c:Chunk)-[:MENTIONS]->(def:Definition) WHERE (c.leiden_community) IS NOT NULL AND def.degree <= 30\n",
    "WITH c.leiden_community AS leiden_community, def.term as definition, count(*) as cnt\n",
    "WHERE cnt > 7\n",
    "RETURN leiden_community, definition, cnt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = df.pivot(index=\"definition\", columns=\"leiden_community\", values=\"cnt\").fillna(0).sort_index()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(pivot_table, cmap=\"Blues\", yticklabels=True, linewidths=0.5)\n",
    "plt.xlabel(\"Community\")\n",
    "plt.ylabel(\"Definition\")\n",
    "plt.title(\"Definition Distribution Heatmap per Community\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
