{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-Chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from neo4j import Query, GraphDatabase, RoutingControl, Result\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file = 'credentials.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(env_file):\n",
    "    load_dotenv(env_file, override=True)\n",
    "\n",
    "    # Neo4j\n",
    "    HOST = os.getenv('NEO4J_URI')\n",
    "    USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "    PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "    DATABASE = os.getenv('NEO4J_DATABASE')\n",
    "\n",
    "    # AI\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    os.environ['OPENAI_API_KEY']=OPENAI_API_KEY\n",
    "    LLM = os.getenv('LLM')\n",
    "    EMBEDDINGS_MODEL = os.getenv('EMBEDDINGS_MODEL')\n",
    "else:\n",
    "    print(f\"File {env_file} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Connection to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup connection to the database with the Python Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "    HOST,\n",
    "    auth=(USERNAME, PASSWORD)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count\n",
       "0    917"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (n) RETURN COUNT(n) as Count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RAG-application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the the chatbot we both need an Embedding-model and LLM. Create both below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=EMBEDDINGS_MODEL,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=LLM)\n",
    "llm.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the difference between a \"Regular\" Vector Search and GraphRAG we create different retrieval queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_vector_search(search_prompt):\n",
    "    query_vector = embedding_model.embed_query(search_prompt)\n",
    "    \n",
    "    similarity_query = \"\"\" \n",
    "        CALL db.index.vector.queryNodes(\"chunk-embeddings\", 5, $query_vector) YIELD node, score\n",
    "        WITH node as chunk, score ORDER BY score DESC\n",
    "        MATCH (d:Document)<-[:PART_OF]-(chunk)\n",
    "        RETURN score, d.file_name as file_name, chunk.page as page, chunk.chunk AS chunk\n",
    "       \"\"\"\n",
    "    results = driver.execute_query(\n",
    "        similarity_query,\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        query_vector=query_vector,\n",
    "        result_transformer_= lambda r: r.to_df()\n",
    "    )\n",
    "    print(results)\n",
    "#    context = \"Related documents: \\n\\n\" + \"\\n\\n\".join([\"file_name: \" + record['file_name'] + \"\\n\" + \"page: \" + str(record['page'] + 1) + \"\\n\" + \"text: \" + record['chunk'] + \"\\n\" for record in results.records])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_context_graphrag(search_prompt):\n",
    "    \n",
    "#     return context, definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to retrieve the client name from a client id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for vector search (without definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_vector_search(search_prompt, context):\n",
    "    prompt_template = \"\"\"\n",
    "\n",
    "    You are a chatbot on Rabobank product. Your goal is to help people with questions on product policies.  \n",
    "    A user will come to you with questions on their policy. Their questions must be answered based on the relevant documents of the policy.\n",
    "    \n",
    "    The question is the following: \n",
    "    {search_prompt}\n",
    "    Always respond in the language in which the question was asked. So, do not respond in a different language.\n",
    "    \n",
    "    The context is the following: \n",
    "    {context}\n",
    "    \n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    theprompt = prompt.format_prompt(search_prompt=search_prompt, context=context)\n",
    "    return theprompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some examples to test the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every example there can be chosen between GraphRAG and vector search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score                                        file_name  page  \\\n",
      "0  0.565576  Payment and Online Services Terms Sept 2022.pdf    33   \n",
      "1  0.565462  Payment and Online Services Terms Sept 2022.pdf    58   \n",
      "2  0.563671  Payment and Online Services Terms Sept 2022.pdf    32   \n",
      "3  0.563387  Payment and Online Services Terms Sept 2022.pdf    49   \n",
      "4  0.563151  Payment and Online Services Terms Sept 2022.pdf    36   \n",
      "\n",
      "                                               chunk  \n",
      "0  te geven, aangifte te doen bij de politie of i...  \n",
      "1  biljetten overdragen aan de autoriteiten. Ook ...  \n",
      "2  Wij delen u de resultaten mee. De kosten hierv...  \n",
      "3  Hoofdstuk 6 Betalen en ontvangen Voorwaarden b...  \n",
      "4  Hoofdstuk 5 Betaalopdrachten37 Voorwaarden bet...  \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "De term \"Rabofoon\" verwijst naar een telefonische dienst van Rabobank waarmee klanten hun bankzaken kunnen regelen via de telefoon. Het is een manier om toegang te krijgen tot bankdiensten zonder fysiek naar een bankfiliaal te gaan of gebruik te maken van online bankieren. Voor specifieke details over de Rabofoon, zoals hoe het werkt of welke diensten beschikbaar zijn, zou je de relevante secties in de documentatie van Rabobank moeten raadplegen.\n"
     ]
    }
   ],
   "source": [
    "search_prompt = 'Wat wordt bedoelt met de Rabofoon?'\n",
    "\n",
    "context = get_context_vector_search(search_prompt)\n",
    "theprompt = generate_prompt_vector_search(search_prompt, context)\n",
    "llm(theprompt.to_messages()).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Chatbot that uses RAG and GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code is coming from Gradio documentation: [Creating a custom chatbot with blocks](https://www.gradio.app/guides/creating-a-custom-chatbot-with-blocks#add-streaming-to-your-chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score                                        file_name  page  \\\n",
      "0  0.565131  Payment and Online Services Terms Sept 2022.pdf    33   \n",
      "1  0.561806  Payment and Online Services Terms Sept 2022.pdf    50   \n",
      "2  0.561150  Payment and Online Services Terms Sept 2022.pdf    50   \n",
      "3  0.560151  Payment and Online Services Terms Sept 2022.pdf    32   \n",
      "4  0.560105  Payment and Online Services Terms Sept 2022.pdf    32   \n",
      "\n",
      "                                               chunk  \n",
      "0  te geven, aangifte te doen bij de politie of i...  \n",
      "1  138.  Betalen door uw betaalpas- of creditcard...  \n",
      "2  139. Hoe betaalt u met een overschrijvingsform...  \n",
      "3  Wij delen u de resultaten mee. De kosten hierv...  \n",
      "4  Neem dan eerst contact met ons op. Ga naar rab...  \n"
     ]
    }
   ],
   "source": [
    "def user(user_message, history):\n",
    "    return \"\", history + [[user_message, None]]\n",
    "\n",
    "def get_answer(search_prompt, rag_method):\n",
    "    if rag_method == \"Vector-Search\":\n",
    "        context = get_context_vector_search(search_prompt)\n",
    "        theprompt = generate_prompt_vector_search(search_prompt, context)\n",
    "    else: \n",
    "    # rag_method == \"GraphRAG\"\n",
    "        context, definitions = get_context_graphrag(search_prompt)\n",
    "        theprompt = generate_prompt_graphrag(search_prompt, context, definitions)\n",
    "    messages = llm(theprompt.to_messages())\n",
    "    return messages.content\n",
    "\n",
    "def bot(history, rag_method):\n",
    "    bot_message = get_answer(history[-1][0], rag_method)\n",
    "    history[-1][1] = \"\"\n",
    "    for character in bot_message:\n",
    "        history[-1][1] += character\n",
    "        time.sleep(0.01)\n",
    "        yield history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"Chatbot with RAG\", \n",
    "        avatar_images=[\"https://png.pngtree.com/png-vector/20220525/ourmid/pngtree-concept-of-facial-animal-avatar-chatbot-dog-chat-machine-illustration-vector-png-image_46652864.jpg\",\"https://d-cb.jc-cdn.com/sites/crackberry.com/files/styles/larger/public/article_images/2023/08/openai-logo.jpg\"]\n",
    "    )\n",
    "    msg = gr.Textbox(label=\"Message\")\n",
    "    rag_method = gr.Radio([\"Vector-Search\", \"GraphRAG\"], label=\"RAG-method:\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, [chatbot, rag_method], chatbot\n",
    "    )\n",
    "    \n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "    \n",
    "demo.queue()\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have the light-mode for the chatbot paste the following after the URL: /?__theme=light"
   ]
  }
 ],
 "metadata": {
  "createdOn": 1712323594898,
  "creator": "admin",
  "customFields": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "modifiedBy": "admin",
  "tags": [],
  "versionNumber": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
