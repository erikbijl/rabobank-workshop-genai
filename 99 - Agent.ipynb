{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - GraphRAG and Agents\n",
    "\n",
    "This module has the following objectives:\n",
    "- Experiment with queries for an Agent\n",
    "- Define Tooling\n",
    "- Create an agents with the available tools\n",
    "- Chatbot for an Agent\n",
    "- Text2Cypher (if we got time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FHKg4DVZiQ98"
   },
   "outputs": [],
   "source": [
    "#!pip install graphdatascience neo4j dotenv openai langchain, langgraph, pydantic, gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import our usual suspects (and some more...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import Query, GraphDatabase, RoutingControl, Result\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from openai import OpenAI\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import functools\n",
    "from langchain_core.tools import tool\n",
    "import gradio as gr\n",
    "import time\n",
    "from json import loads, dumps\n",
    "from openai import OpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, Graph, START, END\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynPe6RLRWSKd"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa61u1jfyk3t"
   },
   "source": [
    "Load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file = 'credentials.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CHR_0lmElZ-R"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(env_file):\n",
    "    load_dotenv(env_file, override=True)\n",
    "\n",
    "    # Neo4j\n",
    "    HOST = os.getenv('NEO4J_URI')\n",
    "    USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "    PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "    DATABASE = os.getenv('NEO4J_DATABASE')\n",
    "\n",
    "    # AI\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    os.environ['OPENAI_API_KEY']=OPENAI_API_KEY\n",
    "    LLM = os.getenv('LLM')\n",
    "    EMBEDDINGS_MODEL = os.getenv('EMBEDDINGS_MODEL')\n",
    "else:\n",
    "    print(f\"File {env_file} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to neo4j db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "    HOST,\n",
    "    auth=(USERNAME, PASSWORD)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5w4eCb7xZZ-S"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count\n",
       "0   1494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (n) RETURN COUNT(n) as Count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdTfdAyV2ZaR"
   },
   "source": [
    "Test whether we got our constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cdTfdAyV2ZaR"
   },
   "outputs": [],
   "source": [
    "schema_result_df  = driver.execute_query(\n",
    "    'show indexes',\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cdTfdAyV2ZaR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>populationPercent</th>\n",
       "      <th>type</th>\n",
       "      <th>entityType</th>\n",
       "      <th>labelsOrTypes</th>\n",
       "      <th>properties</th>\n",
       "      <th>indexProvider</th>\n",
       "      <th>owningConstraint</th>\n",
       "      <th>lastRead</th>\n",
       "      <th>readCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>chunk-embeddings</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>VECTOR</td>\n",
       "      <td>NODE</td>\n",
       "      <td>[Chunk]</td>\n",
       "      <td>[embedding]</td>\n",
       "      <td>vector-2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-05-14T14:38:01.962000000+00:00</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>index_343aff4e</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>LOOKUP</td>\n",
       "      <td>NODE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>token-lookup-1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-05-14T14:56:08.870000000+00:00</td>\n",
       "      <td>3813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>index_f7700477</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>LOOKUP</td>\n",
       "      <td>RELATIONSHIP</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>token-lookup-1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-05-14T14:56:09.496000000+00:00</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>unique_chunk</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RANGE</td>\n",
       "      <td>NODE</td>\n",
       "      <td>[Chunk]</td>\n",
       "      <td>[id]</td>\n",
       "      <td>range-1.0</td>\n",
       "      <td>unique_chunk</td>\n",
       "      <td>2025-05-14T14:38:01.989000000+00:00</td>\n",
       "      <td>11035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>unique_document</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RANGE</td>\n",
       "      <td>NODE</td>\n",
       "      <td>[Document]</td>\n",
       "      <td>[id]</td>\n",
       "      <td>range-1.0</td>\n",
       "      <td>unique_document</td>\n",
       "      <td>2025-05-13T12:31:28.842000000+00:00</td>\n",
       "      <td>2742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              name   state  populationPercent    type    entityType  \\\n",
       "0   6  chunk-embeddings  ONLINE              100.0  VECTOR          NODE   \n",
       "1   0    index_343aff4e  ONLINE              100.0  LOOKUP          NODE   \n",
       "2   1    index_f7700477  ONLINE              100.0  LOOKUP  RELATIONSHIP   \n",
       "3   4      unique_chunk  ONLINE              100.0   RANGE          NODE   \n",
       "4   2   unique_document  ONLINE              100.0   RANGE          NODE   \n",
       "\n",
       "  labelsOrTypes   properties     indexProvider owningConstraint  \\\n",
       "0       [Chunk]  [embedding]        vector-2.0             None   \n",
       "1          None         None  token-lookup-1.0             None   \n",
       "2          None         None  token-lookup-1.0             None   \n",
       "3       [Chunk]         [id]         range-1.0     unique_chunk   \n",
       "4    [Document]         [id]         range-1.0  unique_document   \n",
       "\n",
       "                              lastRead  readCount  \n",
       "0  2025-05-14T14:38:01.962000000+00:00        113  \n",
       "1  2025-05-14T14:56:08.870000000+00:00       3813  \n",
       "2  2025-05-14T14:56:09.496000000+00:00        104  \n",
       "3  2025-05-14T14:38:01.989000000+00:00      11035  \n",
       "4  2025-05-13T12:31:28.842000000+00:00       2742  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_result_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=EMBEDDINGS_MODEL,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text-embedding-ada-002'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents with GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create a Retrieval agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Skill(BaseModel):\n",
    "#     \"\"\"\n",
    "#     Represents a professional skill or knowledge of a person.\n",
    "#     \"\"\"\n",
    "#     name: str = Field(..., description=\"Sortened name of the skill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Product or Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_product_customer_prompt = \"\"\"\n",
    "As an intelligent assistant, your primary objective is to find either a customer name or product from the text submitted. \n",
    "The goal is to retrieve either the product on which someone is asking a question. Or the customer name such that we can find the products from their. \n",
    "Please only return the product name that is extracted. \n",
    "\n",
    "Examples:\n",
    "#####\n",
    "User: I got a question about my savings account. \n",
    "Assistant: Product: savings account\n",
    "#####\n",
    "#####\n",
    "User: My name is Jan Blok and I got a question. \n",
    "Assistant: Customer: Jan Blok\n",
    "#####\n",
    "#####\n",
    "User: What is the policy on account? \n",
    "Assistant: Need more information\n",
    "#####\n",
    "\"\"\"\n",
    "\n",
    "def retrieve_product_or_customer_from_text(question):\n",
    "    \"\"\"Retrieve either products or customers from the text given by the user\"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=LLM,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": retrieve_product_customer_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "#        response_format=DefinitionList,\n",
    "    )\n",
    "    return response.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product: savings account'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_product_or_customer_from_text(\"I got a question about my savings account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Need more information'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_product_or_customer_from_text(\"Can I have overdraft on my account?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Customer: Erik Bijl'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_product_or_customer_from_text(\"I'm Erik Bijl, can I have overdraft on my account?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_products() -> pd.DataFrame:\n",
    "    \"\"\"Retrieve the products in the database. Products are specified with name. \"\"\"\n",
    "    return driver.execute_query(\n",
    "        \"\"\"\n",
    "        MATCH (p:ProductType)\n",
    "        RETURN p.name as name\n",
    "        \"\"\",\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        result_transformer_= lambda r: r.to_df(),\n",
    "    )['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpaarRekening',\n",
       " 'DirectRekening',\n",
       " 'Kortlopende Reis',\n",
       " 'BeleggersRekening',\n",
       " 'RaboBusiness Banking']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_products_prompt = \"\"\"\n",
    "As an intelligent assistant, your primary objective is to map a product name to product names in the database.\n",
    "\n",
    "Examples:\n",
    "#####\n",
    "Product: savings account. \n",
    "Database Products: ['SpaarRekening', 'DirectRekening', 'Kortlopende Reis', 'BeleggersRekening', 'RaboBusiness Banking']\n",
    "Assistant: Product: SpaarRekening\n",
    "#####\n",
    "#####\n",
    "Product: Direct Rekening. \n",
    "Database Products: ['SpaarRekening', 'DirectRekening', 'Kortlopende Reis', 'BeleggersRekening', 'RaboBusiness Banking']Assistant: Customer: Jan Blok\n",
    "Assistant: Product: DirectRekening\n",
    "\n",
    "#####\n",
    "#####\n",
    "Product: Reis verzekering. \n",
    "Database Products: ['SpaarRekening', 'DirectRekening', 'Kortlopende Reis', 'BeleggersRekening', 'RaboBusiness Banking']Assistant: Customer: Jan Blok\n",
    "Assistant: Product: Kortlopende Reis\n",
    "#####\n",
    "\"\"\"\n",
    "\n",
    "def map_product_to_database_products(product) -> str:\n",
    "    \"\"\"Map products from the user question to the actual products in the database.\"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=LLM,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": map_products_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"Product: \" + product},\n",
    "            {\"role\": \"user\", \"content\": \"Database Products: \" + str(retrieve_products())},\n",
    "            \n",
    "        ],\n",
    "#        response_format=DefinitionList,\n",
    "    )\n",
    "    return response.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product: SpaarRekening'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_product_to_database_products('savings account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_document_from_product(product_name) -> pd.DataFrame:\n",
    "    \"\"\"Retrieve the documents of products in the database. Products are specified with their name. \"\"\"\n",
    "    return driver.execute_query(\n",
    "        \"\"\"\n",
    "        MATCH (p:ProductType)<-[:RELATED_TO]-(d:Document)\n",
    "        WHERE LOWER(p.name) = LOWER($product_name)\n",
    "        RETURN d.file_name\n",
    "        \"\"\",\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        product_name = product_name,\n",
    "        result_transformer_= lambda r: r.to_df(),\n",
    "    ).iloc[0]['d.file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rabo SpaarRekening 2020.pdf'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_document_from_product('SpaarRekening')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_graphrag(document, search_prompt):\n",
    "\n",
    "    query_vector = embedding_model.embed_query(search_prompt)\n",
    "    \n",
    "    similarity_query = \"\"\" \n",
    "        CALL db.index.vector.queryNodes(\"chunk-embeddings\", 30, $query_vector) YIELD node, score\n",
    "        WITH node as chunk, score ORDER BY score DESC\n",
    "        MATCH (d:Document {file_name: $document})<-[:PART_OF]-(chunk)\n",
    "        WITH score, d, chunk LIMIT 5\n",
    "        RETURN score, d.file_name as file_name, chunk.id as chunk_id, chunk.page as page, chunk.chunk_eng AS chunk\n",
    "       \"\"\"\n",
    "    results = driver.execute_query(\n",
    "        similarity_query,\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        document = document,\n",
    "        query_vector=query_vector,\n",
    "        result_transformer_= lambda r: r.to_df()\n",
    "    )\n",
    "\n",
    "    chunk_ids = list(set(results['chunk_id'].to_list()))\n",
    "\n",
    "    results = results.to_json(orient=\"records\")\n",
    "    parsed = loads(results)\n",
    "    context = dumps(parsed, indent=4)\n",
    "\n",
    "    definition_query = \"\"\"    \n",
    "        MATCH (c:Chunk)-[:MENTIONS]->(d:Definition)\n",
    "        WHERE c.id in $chunk_ids\n",
    "        RETURN DISTINCT d.term as term, d.description as description\n",
    "    \"\"\"\n",
    "    results = driver.execute_query(\n",
    "        definition_query,\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        chunk_ids=chunk_ids,\n",
    "        result_transformer_= lambda r: r.to_df()\n",
    "    )\n",
    "    results = results.to_json(orient=\"records\")\n",
    "    parsed = loads(results)\n",
    "    definitions = dumps(parsed, indent=4)\n",
    "    return context, definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_graphrag(search_prompt, context, definitions):\n",
    "    prompt_template = \"\"\"\n",
    "\n",
    "    You are a chatbot on Rabobank product. Your goal is to help people with questions on product policies.  \n",
    "    A user will come to you with questions on their policy. Their questions must be answered based on the relevant documents of the policy.\n",
    "    Respond in English. \n",
    "\n",
    "    The question is the following: \n",
    "    {search_prompt}\n",
    "    \n",
    "    Always respond in the language in which the question was asked. So, do not respond in a different language.\n",
    "    \n",
    "    The context is the following: \n",
    "    {context}\n",
    "\n",
    "    The definitions are the following: \n",
    "    {definitions}\n",
    "    \n",
    "    Please end your message with listing your sources with file name and page number. \n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    theprompt = prompt.format_prompt(search_prompt=search_prompt, context=context, definitions=definitions)\n",
    "    return theprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_search_in_document(document, search_prompt) -> pd.DataFrame:\n",
    "    \"\"\"Peform a search in the document to search relevant text and definitions to answer a user question. The document first needs to be determined before a search should be performed.\"\"\"\n",
    "\n",
    "    context, definitions = get_context_graphrag(document, search_prompt)\n",
    "    \n",
    "    return context, definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(state):\n",
    "    context, definitions = perform_search_in_document(state['document'], state['question'])\n",
    "    theprompt = generate_prompt_graphrag(state['question'], context, definitions)\n",
    "    llm(theprompt.to_messages()).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=LLM, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/vn55w75s41703t1w811dtf080000gp/T/ipykernel_54575/2830703966.py:4: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm(theprompt.to_messages()).pretty_print()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The rules for a shared savings account, also known as a joint account, with Rabobank are as follows:\n",
      "\n",
      "1. **Joint Account Definition**: If the savings account has multiple account holders, it is considered a joint account. This is only different if it has been agreed with the bank that it is a joint-and account.\n",
      "\n",
      "2. **Communication**: Rabobank only needs to inform one account holder, either in writing or electronically. It is the responsibility of the informed account holder to immediately share any information with the other account holders. All account holders are bound by the information provided to one of them, even if they do not live at the same address.\n",
      "\n",
      "3. **Notifications**: If one account holder informs the bank or makes a notification, it is assumed that this is done on behalf of all account holders.\n",
      "\n",
      "4. **Usage Restrictions**: In the event of bankruptcy, legal debt restructuring, or seizure, none of the account holders may use the savings account. If one account holder is affected by these situations, the bank reserves the right to offset any debt owed by one of the account holders with the balance in the account.\n",
      "\n",
      "These rules ensure that all account holders are equally responsible and informed about the account's status and any actions taken by the bank.\n",
      "\n",
      "**Sources**:\n",
      "- Rabo SpaarRekening 2020.pdf, Page 8\n",
      "- Rabo SpaarRekening 2020.pdf, Page 10\n"
     ]
    }
   ],
   "source": [
    "answer_question({'document': \"Rabo SpaarRekening 2020.pdf\", 'question': \"What are the rules for shared savings account?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    input: str\n",
    "    question: str\n",
    "    product: str\n",
    "    customer: str\n",
    "    document: str\n",
    "\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "# no-op node that should be interrupted on\n",
    "def human_feedback(state: State):\n",
    "    pass\n",
    "\n",
    "\n",
    "def retrieve_product_customer(state):\n",
    "    result = retrieve_product_or_customer_from_text(state['input'])\n",
    "    if 'Customer: ' in result:\n",
    "        customer = result.split('Customer: ')[1]\n",
    "        print('It looks like you are the following customer: ' + customer)\n",
    "        state['customer'] = customer\n",
    "    elif 'Product: ' in result:\n",
    "        product = result.split('Product: ')[1]\n",
    "        print('It sounds like you got a question on the following product: ' + product)\n",
    "        state['product'] = product\n",
    "    return state\n",
    "\n",
    "def user_feedback(state):\n",
    "    print(\"I couldn't find information to start the flow. Could you specify a product on which you have questions or your customer name?\")\n",
    "    return state \n",
    "    \n",
    "def map_product_to_db(state):\n",
    "    result = map_product_to_database_products(state['product'])\n",
    "    product = result.split('Product: ')[1]\n",
    "    state['product'] = product\n",
    "    print(\"I have found the following product in the database: \" + product)\n",
    "    return state\n",
    "\n",
    "def retrieve_document(state):\n",
    "    result = retrieve_document_from_product(state['product'])\n",
    "    state['document'] = result\n",
    "    print(\"I found the following document on the product: \" + result)\n",
    "    return state\n",
    "\n",
    "def tools_condition(state) -> Literal[\"user_feedback\", \"map_product\"]: \n",
    "    if (state.get('product') is None):\n",
    "        return \"user_feedback\"\n",
    "    else: \n",
    "        return \"map_product\"\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"retrieve_product_customer\", retrieve_product_customer)\n",
    "builder.add_node(\"user_feedback\", user_feedback)\n",
    "builder.add_node(\"map_product\", map_product_to_db)\n",
    "builder.add_node(\"retrieve_document\", retrieve_document)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"answer_question\", answer_question)\n",
    "\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"retrieve_product_customer\")\n",
    "builder.add_conditional_edges(\"retrieve_product_customer\", tools_condition)\n",
    "builder.add_edge(\"user_feedback\", END)\n",
    "builder.add_edge(\"map_product\", \"retrieve_document\")\n",
    "builder.add_edge(\"retrieve_document\", \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"answer_question\")\n",
    "builder.add_edge(\"answer_question\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Add\n",
    "graph = builder.compile(checkpointer=memory, interrupt_before=[\"human_feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.get_graph().draw_mermaid_png()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   +-----------+                   \n",
      "                   | __start__ |                   \n",
      "                   +-----------+                   \n",
      "                          *                        \n",
      "                          *                        \n",
      "                          *                        \n",
      "           +---------------------------+           \n",
      "           | retrieve_product_customer |           \n",
      "           +---------------------------+           \n",
      "                 ...            ...                \n",
      "               ..                  ...             \n",
      "             ..                       ..           \n",
      "   +-------------+                      ..         \n",
      "   | map_product |                       .         \n",
      "   +-------------+                       .         \n",
      "          *                              .         \n",
      "          *                              .         \n",
      "          *                              .         \n",
      "+-------------------+                    .         \n",
      "| retrieve_document |                    .         \n",
      "+-------------------+                    .         \n",
      "          *                              .         \n",
      "          *                              .         \n",
      "          *                              .         \n",
      "  +----------------+                     .         \n",
      "  | human_feedback |                     .         \n",
      "  +----------------+                     .         \n",
      "          *                              .         \n",
      "          *                              .         \n",
      "          *                              .         \n",
      " +-----------------+            +---------------+  \n",
      " | answer_question |            | user_feedback |  \n",
      " +-----------------+            +---------------+  \n",
      "                 ***            ***                \n",
      "                    **        **                   \n",
      "                      **    **                     \n",
      "                    +---------+                    \n",
      "                    | __end__ |                    \n",
      "                    +---------+                    \n"
     ]
    }
   ],
   "source": [
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'I got a question on my savings account, what are the rules for a shared account?'}\n",
      "It sounds like you got a question on the following product: savings account\n",
      "{'input': 'I got a question on my savings account, what are the rules for a shared account?', 'product': 'savings account'}\n",
      "I have found the following product in the database: SpaarRekening\n",
      "{'input': 'I got a question on my savings account, what are the rules for a shared account?', 'product': 'SpaarRekening'}\n",
      "I found the following document on the product: Rabo SpaarRekening 2020.pdf\n",
      "{'input': 'I got a question on my savings account, what are the rules for a shared account?', 'product': 'SpaarRekening', 'document': 'Rabo SpaarRekening 2020.pdf'}\n",
      "StateSnapshot(values={'input': 'I got a question on my savings account, what are the rules for a shared account?', 'product': 'SpaarRekening', 'document': 'Rabo SpaarRekening 2020.pdf'}, next=('human_feedback',), config={'configurable': {'thread_id': '25', 'checkpoint_ns': '', 'checkpoint_id': '1f030d5f-70b0-662c-8003-b7e6b80aef60'}}, metadata={'source': 'loop', 'writes': {'retrieve_document': {'input': 'I got a question on my savings account, what are the rules for a shared account?', 'product': 'SpaarRekening', 'document': 'Rabo SpaarRekening 2020.pdf'}}, 'thread_id': '25', 'step': 3, 'parents': {}}, created_at='2025-05-14T15:13:17.934695+00:00', parent_config={'configurable': {'thread_id': '25', 'checkpoint_ns': '', 'checkpoint_id': '1f030d5f-709b-6b14-8002-180a5001881a'}}, tasks=(PregelTask(id='aa7da653-7484-e58e-5656-879e96a985ba', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(event)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(graph\u001b[38;5;241m.\u001b[39mget_state(thread))\n\u001b[0;32m----> 9\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease raise your question on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph\u001b[38;5;241m.\u001b[39mget_state(thread)\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m graph\u001b[38;5;241m.\u001b[39mupdate_state(thread, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_input}, as_node\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_feedback\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m graph\u001b[38;5;241m.\u001b[39mget_state(thread)\u001b[38;5;241m.\u001b[39mnext\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "initial_input = {\"input\" : \"I got a question on my savings account, what are the rules for a shared account?\"}\n",
    "\n",
    "thread  = {\"configurable\": {\"thread_id\": \"25\"}}\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print(event)\n",
    "\n",
    "print(graph.get_state(thread))\n",
    "\n",
    "user_input = input(f\"Please raise your question on {graph.get_state(thread).values['product']}: \")\n",
    "\n",
    "graph.update_state(thread, {\"question\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "graph.get_state(thread).next\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'My name is Eva Meijer, I got a question what my interest rate is on my savings account. '}\n",
      "It looks like you are the following customer: Eva Meijer\n",
      "{'input': 'My name is Eva Meijer, I got a question what my interest rate is on my savings account. ', 'customer': 'Eva Meijer'}\n",
      "I couldn't find information to start the flow. Could you specify a product on which you have questions or your customer name?\n",
      "{'input': 'My name is Eva Meijer, I got a question what my interest rate is on my savings account. ', 'customer': 'Eva Meijer'}\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"input\" : \"My name is Eva Meijer, I got a question what my interest rate is on my savings account. \"}\n",
    "\n",
    "thread  = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import io\n",
    "import contextlib\n",
    "\n",
    "threads = {}\n",
    "\n",
    "def chat_interface(user_input, chat_history=[], thread_id=\"default\"):\n",
    "    # Reuse or initialize thread\n",
    "    if thread_id not in threads:\n",
    "        threads[thread_id] = {\n",
    "            \"configurable\": {\"thread_id\": thread_id},\n",
    "            \"step\": \"initial\"\n",
    "        }\n",
    "\n",
    "    thread = threads[thread_id]\n",
    "\n",
    "    # Capture all print output from graph steps\n",
    "    f = io.StringIO()\n",
    "    with contextlib.redirect_stdout(f):\n",
    "        if thread[\"step\"] == \"initial\":\n",
    "\n",
    "            initial_input = {\"input\": user_input}\n",
    "            for _ in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "                pass\n",
    "\n",
    "            thread[\"step\"] = \"waiting_for_question\"\n",
    "            output_text = f.getvalue().strip()\n",
    "\n",
    "            # Determine if human input is needed\n",
    "            next_node = graph.get_state(thread).next\n",
    "            if next_node == \"human_feedback\":\n",
    "                print(\"HELLOOOO\")\n",
    "                product = graph.get_state(thread).values.get(\"product\", \"the product\")\n",
    "                assistant_message = f\"{output_text}\\nPlease clarify your question on **{product}**.\"\n",
    "                print(f\"Please clarify your question on {product}\")\n",
    "                return \"\", chat_history + [(user_input, assistant_message)]\n",
    "\n",
    "            return \"\", chat_history + [(user_input, output_text)]\n",
    "\n",
    "        elif thread[\"step\"] == \"waiting_for_question\":\n",
    "            graph.update_state(thread, {\"question\": user_input}, as_node=\"human_feedback\")\n",
    "            thread[\"step\"] = \"done\"\n",
    "\n",
    "            for _ in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "                pass\n",
    "\n",
    "            output_text = f.getvalue().strip()\n",
    "            final_state = graph.get_state(thread)\n",
    "            final_answer = final_state.values.get(\"answer\", \"[No answer generated]\")\n",
    "\n",
    "            assistant_message = f\"{output_text}\\n\\nü§ñ **Answer:** {final_answer}\"\n",
    "            return \"\", chat_history + [(user_input, assistant_message)]\n",
    "\n",
    "        else:\n",
    "            return \"\", chat_history + [(user_input, \"‚ö†Ô∏è Conversation is complete. Please reset to start again.\")]\n",
    "\n",
    "    return \"\", chat_history + [(user_input, \"[Unexpected error occurred]\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikbijl/anaconda3/lib/python3.11/site-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(label=\"Your message\")\n",
    "    send_btn = gr.Button(\"Send\")\n",
    "    reset_btn = gr.Button(\"Reset\")\n",
    "\n",
    "    def respond(message, chat_history):\n",
    "        return chat_interface(message, chat_history)\n",
    "\n",
    "    def reset():\n",
    "        threads.clear()\n",
    "        return []\n",
    "\n",
    "    send_btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    reset_btn.click(reset, outputs=[chatbot])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Products in the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_products() -> pd.DataFrame:\n",
    "    \"\"\"Retrieve the products in the database. Products are specified with name. \"\"\"\n",
    "    return driver.execute_query(\n",
    "        \"\"\"\n",
    "        MATCH (p:ProductType)\n",
    "        RETURN p.name as name\n",
    "        \"\"\",\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        result_transformer_= lambda r: r.to_df(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpaarRekening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DirectRekening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kortlopende Reis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BeleggersRekening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RaboBusiness Banking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name\n",
       "0         SpaarRekening\n",
       "1        DirectRekening\n",
       "2      Kortlopende Reis\n",
       "3     BeleggersRekening\n",
       "4  RaboBusiness Banking"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_products() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_document_from_product(product_name) -> pd.DataFrame:\n",
    "    \"\"\"Retrieve the documents of products in the database. Products are specified with their name. \"\"\"\n",
    "    return driver.execute_query(\n",
    "        \"\"\"\n",
    "        MATCH (p:Product)-[:OF_TYPE]->(:ProductType)<-[:RELATED_TO]-(d:Document)\n",
    "        WHERE LOWER(p.name) = LOWER($product_name)\n",
    "        RETURN d.file_name LIMIT 1\n",
    "        \"\"\",\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        product_name = product_name,\n",
    "        result_transformer_= lambda r: r.to_df(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d.file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interpolis Short-Term Travel Insurance.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  d.file_name\n",
       "0  Interpolis Short-Term Travel Insurance.pdf"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_document_from_product('Kortlopende Reis Product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=LLM, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieve_products_of_customer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     retrieve_products, \n\u001b[1;32m      3\u001b[0m     perform_search_in_document,\n\u001b[1;32m      4\u001b[0m     retrieve_document_from_product,\n\u001b[0;32m----> 5\u001b[0m     retrieve_products_of_customer,\n\u001b[1;32m      6\u001b[0m     map_product_to_database_products,\n\u001b[1;32m      7\u001b[0m     retrieve_product_or_customer_from_text\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m     10\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind_tools(tools)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrieve_products_of_customer' is not defined"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    retrieve_products, \n",
    "    perform_search_in_document,\n",
    "    retrieve_document_from_product,\n",
    "    retrieve_products_of_customer,\n",
    "    map_product_to_database_products,\n",
    "    retrieve_product_or_customer_from_text\n",
    "]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '''\n",
    "    As an intelligent assistant, your primary objective is to find answeres to questions on products. \n",
    "    The questions can be answered by looking in the documentation of these products (context_search).\n",
    "    However, before finding the right documentation we need to find the products on which the questions are asked. Find this out first.\n",
    "    If this is not clear kindly ask the customer that you are there to help and you need either a customer name or product.\n",
    "    You can find the related documents from the user question directly or you can find it from a customer name. \n",
    "    In case you have found the customer name, just query the database with the client name to find the products the client is having questions about. \n",
    "    You can answer only on the products that are actually in the database. So, map the products to the ones in the database.\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='3bf26016-ecd4-4974-8716-8388d7054a87'),\n",
       " AIMessage(content='Please provide either the name of the product or the customer name so I can assist you with your question.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 397, 'total_tokens': 420, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'finish_reason': 'stop', 'logprobs': None}, id='run-12bf0b2a-50b7-4fa3-b989-e902b409577d-0', usage_metadata={'input_tokens': 397, 'output_tokens': 23, 'total_tokens': 420, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run some examples! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_to_agent(question):\n",
    "    for step in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=question)]},\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Can I have overdraft on my account?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can I have overdraft on my account?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Please provide me with either the name of the product or the customer name so I can assist you better.\n"
     ]
    }
   ],
   "source": [
    "ask_to_agent(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a chatbot with the agent providing the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* Running on public URL: https://124eec5ce9b2cdf8b5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://124eec5ce9b2cdf8b5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user(user_message, history):\n",
    "    if history is None:\n",
    "        history = []\n",
    "    history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    return \"\", history\n",
    "\n",
    "def get_answer(history):\n",
    "    steps = []\n",
    "    full_prompt = \"\\n\".join([f\"{msg['role'].capitalize()}: {msg['content']}\" for msg in history])\n",
    "    \n",
    "    for step in agent_executor.stream(\n",
    "            {\"messages\": [HumanMessage(content=full_prompt)]},\n",
    "            stream_mode=\"values\",\n",
    "    ):\n",
    "        step[\"messages\"][-1].pretty_print()\n",
    "        steps.append(step[\"messages\"][-1].content)\n",
    "    \n",
    "    return steps[-1]\n",
    "\n",
    "def bot(history):\n",
    "    bot_message = get_answer(history)\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "\n",
    "    for character in bot_message:\n",
    "        history[-1][\"content\"] += character\n",
    "        time.sleep(0.01)\n",
    "        yield history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"Chatbot on a Graph\",\n",
    "        avatar_images=[\n",
    "            \"https://png.pngtree.com/png-vector/20220525/ourmid/pngtree-concept-of-facial-animal-avatar-chatbot-dog-chat-machine-illustration-vector-png-image_46652864.jpg\",\n",
    "            \"https://d-cb.jc-cdn.com/sites/crackberry.com/files/styles/larger/public/article_images/2023/08/openai-logo.jpg\"\n",
    "        ],\n",
    "        type=\"messages\", \n",
    "    )\n",
    "    msg = gr.Textbox(label=\"Message\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, [chatbot], chatbot\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: [], None, chatbot, queue=False)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have the light-mode for the chatbot paste the following after the URL: /?__theme=light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
