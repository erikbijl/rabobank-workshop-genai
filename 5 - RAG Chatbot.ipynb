{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 - RAG-Chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from neo4j import Query, GraphDatabase, RoutingControl, Result\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "from json import loads, dumps\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file = 'credentials.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(env_file):\n",
    "    load_dotenv(env_file, override=True)\n",
    "\n",
    "    # Neo4j\n",
    "    HOST = os.getenv('NEO4J_URI')\n",
    "    USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "    PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "    DATABASE = os.getenv('NEO4J_DATABASE')\n",
    "\n",
    "    # AI\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    os.environ['OPENAI_API_KEY']=OPENAI_API_KEY\n",
    "    LLM = os.getenv('LLM')\n",
    "    EMBEDDINGS_MODEL = os.getenv('EMBEDDINGS_MODEL')\n",
    "else:\n",
    "    print(f\"File {env_file} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Connection to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup connection to the database with the Python Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "    HOST,\n",
    "    auth=(USERNAME, PASSWORD)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count\n",
       "0   1494"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (n) RETURN COUNT(n) as Count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RAG-application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the the chatbot we both need an Embedding-model and LLM. Create both below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=EMBEDDINGS_MODEL,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text-embedding-ada-002'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the difference between a \"Regular\" Vector Search and GraphRAG we create different retrieval queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_vector_search(search_prompt):\n",
    "    query_vector = embedding_model.embed_query(search_prompt)\n",
    "    \n",
    "    similarity_query = \"\"\" \n",
    "        CALL db.index.vector.queryNodes(\"chunk-embeddings\", 5, $query_vector) YIELD node, score\n",
    "        WITH node as chunk, score ORDER BY score DESC\n",
    "        MATCH (d:Document)<-[:PART_OF]-(chunk)\n",
    "        RETURN score, d.file_name as file_name, chunk.id as chunk_id, chunk.page as page, chunk.chunk_eng AS chunk\n",
    "       \"\"\"\n",
    "    results = driver.execute_query(\n",
    "        similarity_query,\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        query_vector=query_vector,\n",
    "        result_transformer_= lambda r: r.to_df()\n",
    "    )\n",
    "    \n",
    "    results = results.to_json(orient=\"records\")\n",
    "    parsed = loads(results)\n",
    "    context = dumps(parsed, indent=2)\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_graphrag(search_prompt):\n",
    "\n",
    "    query_vector = embedding_model.embed_query(search_prompt)\n",
    "    \n",
    "    similarity_query = \"\"\" \n",
    "        CALL db.index.vector.queryNodes(\"chunk-embeddings\", 5, $query_vector) YIELD node, score\n",
    "        WITH node as chunk, score ORDER BY score DESC\n",
    "        MATCH (d:Document)<-[:PART_OF]-(chunk)\n",
    "        RETURN score, d.file_name as file_name, chunk.id as chunk_id, chunk.page as page, chunk.chunk_eng AS chunk\n",
    "       \"\"\"\n",
    "    results = driver.execute_query(\n",
    "        similarity_query,\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        query_vector=query_vector,\n",
    "        result_transformer_= lambda r: r.to_df()\n",
    "    )\n",
    "\n",
    "    chunk_ids = list(set(results['chunk_id'].to_list()))\n",
    "\n",
    "    results = results.to_json(orient=\"records\")\n",
    "    parsed = loads(results)\n",
    "    context = dumps(parsed, indent=2)\n",
    "\n",
    "    definition_query = \"\"\"    \n",
    "        MATCH (c:Chunk)-[:MENTIONS]->(d:Definition)\n",
    "        WHERE c.id in $chunk_ids\n",
    "        RETURN DISTINCT d.term as term, d.description as description\n",
    "    \"\"\"\n",
    "    results = driver.execute_query(\n",
    "        definition_query,\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.READ,\n",
    "        chunk_ids=chunk_ids,\n",
    "        result_transformer_= lambda r: r.to_df()\n",
    "    )\n",
    "    results = results.to_json(orient=\"records\")\n",
    "    parsed = loads(results)\n",
    "    definitions = dumps(parsed, indent=2)\n",
    "    return context, definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to retrieve the client name from a client id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for vector search (without definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_vector_search(search_prompt, context):\n",
    "    prompt_template = \"\"\"\n",
    "\n",
    "    You are a chatbot on Rabobank product. Your goal is to help people with questions on product policies.  \n",
    "    A user will come to you with questions on their policy. Their questions must be answered based on the relevant documents of the policy.\n",
    "    Respond in English. \n",
    "    \n",
    "    The question is the following: \n",
    "    {search_prompt}\n",
    "    \n",
    "    Always respond in the language in which the question was asked. So, do not respond in a different language.\n",
    "    \n",
    "    The context is the following: \n",
    "    {context}\n",
    "\n",
    "    Please end your message with listing your sources with file name and page number. \n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    theprompt = prompt.format_prompt(search_prompt=search_prompt, context=context)\n",
    "    return theprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_graphrag(search_prompt, context, definitions):\n",
    "    prompt_template = \"\"\"\n",
    "\n",
    "    You are a chatbot on Rabobank product. Your goal is to help people with questions on product policies.  \n",
    "    A user will come to you with questions on their policy. Their questions must be answered based on the relevant documents of the policy.\n",
    "    Respond in English. \n",
    "\n",
    "    The question is the following: \n",
    "    {search_prompt}\n",
    "    \n",
    "    Always respond in the language in which the question was asked. So, do not respond in a different language.\n",
    "    \n",
    "    The context is the following: \n",
    "    {context}\n",
    "\n",
    "    The definitions are the following: \n",
    "    {definitions}\n",
    "    \n",
    "    Please end your message with listing your sources with file name and page number. \n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    theprompt = prompt.format_prompt(search_prompt=search_prompt, context=context, definitions=definitions)\n",
    "    return theprompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some examples to test the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every example there can be chosen between GraphRAG and vector search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Rabofoon is a service provided by Rabobank that allows you to perform banking activities over the phone. If you have access to Rabofoon and it is activated for you, you can give payment orders using the phone's keys. You provide permission for the payment order according to the instructions of Rabofoon, and the order is considered received once you press the confirmation key. Additionally, you can check your current balance, view transactions, and make transfers using Rabofoon. There are no subscription fees for maintaining an agreement for Rabofoon, but calling the Rabofoon number incurs a cost of €0.20 per call.\n",
      "\n",
      "Sources:\n",
      "- Payment and Online Services Terms Sept 2022.pdf, page 51\n",
      "- Rabo SpaarRekening 2020.pdf, page 3\n"
     ]
    }
   ],
   "source": [
    "search_prompt = 'What is meant with the Rabofoon?'\n",
    "\n",
    "context = get_context_vector_search(search_prompt)\n",
    "theprompt = generate_prompt_vector_search(search_prompt, context)\n",
    "llm(theprompt.to_messages()).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The \"Rabofoon\" is a service provided by Rabobank that allows you to give payment orders using the phone's keys. You give permission for the payment order according to the instructions of Rabofoon, and the payment order is received as soon as the confirmation key is pressed. This service can also be used to check the current balance and transactions or make transfers, and it requires a personal access code. There are no subscription fees for maintaining an agreement for the Rabofoon, but calling the Rabofoon incurs a cost of €0.20 per call.\n",
      "\n",
      "**Sources:**\n",
      "- Payment and Online Services Terms Sept 2022.pdf, page 51\n",
      "- Rabo SpaarRekening 2020.pdf, page 3\n"
     ]
    }
   ],
   "source": [
    "search_prompt = 'What is meant with the Rabofoon?'\n",
    "\n",
    "context, definitions = get_context_graphrag(search_prompt)\n",
    "theprompt = generate_prompt_graphrag(search_prompt, context, definitions)\n",
    "llm(theprompt.to_messages()).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Merging, in the context of Rabobank's policies, refers to the process where Rabobank can combine with another legal entity. This process is known as a merger. If Rabobank undergoes a merger, the legal successors of the merged entity can independently exercise all rights and powers against you and fulfill all obligations towards you. This means that the new entity formed from the merger will continue to uphold the rights and responsibilities that Rabobank had with its clients.\n",
      "\n",
      "Sources:\n",
      "- Rabo SpaarRekening 2020.pdf, Page 12\n",
      "- Terms & Conditions for Online Business Services - April 2024.pdf, Page 25\n"
     ]
    }
   ],
   "source": [
    "search_prompt = 'What is merging?'\n",
    "\n",
    "context = get_context_vector_search(search_prompt)\n",
    "theprompt = generate_prompt_vector_search(search_prompt, context)\n",
    "llm(theprompt.to_messages()).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, you can have an overdraft on your account even if you do not have credit. This is referred to as an unauthorized overdraft. You will be charged a variable interest rate on the amount overdrawn, which can change at any time. The interest is composed of several components, including a base rate, surcharges related to capital market developments, individual risk surcharges, ongoing costs, and a profit margin. If you overdraw your account, the amount is immediately due and payable, and you must repay it without any formal notice from the bank.\n",
      "\n",
      "Sources:\n",
      "- Payment and Online Services Terms Sept 2022.pdf, page 19\n",
      "- Payment and Online Services Terms Sept 2022.pdf, page 60\n",
      "- Payment and Online Services Terms Sept 2022.pdf, page 61\n"
     ]
    }
   ],
   "source": [
    "search_prompt = 'Can I have overdraft on my account?'\n",
    "\n",
    "context = get_context_vector_search(search_prompt)\n",
    "theprompt = generate_prompt_vector_search(search_prompt, context)\n",
    "llm(theprompt.to_messages()).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, you can have an overdraft on your account even if you do not have credit. This is referred to as an \"unauthorized overdraft.\" For example, this can occur if the costs of the payment package are deducted from your account. You will be charged a variable interest on this unauthorized overdraft, which can be changed by the bank at any time. Additionally, the amount of the unauthorized overdraft is immediately due and payable, meaning you must repay it immediately without any notice of default or other formality.\n",
      "\n",
      "Sources:\n",
      "- Payment and Online Services Terms Sept 2022.pdf, page 19\n",
      "- Payment and Online Services Terms Sept 2022.pdf, page 61\n"
     ]
    }
   ],
   "source": [
    "search_prompt = 'Can I have overdraft on my account?'\n",
    "\n",
    "context, definitions = get_context_graphrag(search_prompt)\n",
    "theprompt = generate_prompt_graphrag(search_prompt, context, definitions)\n",
    "llm(theprompt.to_messages()).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Chatbot that uses RAG and GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code is coming from Gradio documentation: [Creating a custom chatbot with blocks](https://www.gradio.app/guides/creating-a-custom-chatbot-with-blocks#add-streaming-to-your-chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user(user_message, history):\n",
    "    return \"\", history + [[user_message, None]]\n",
    "\n",
    "def get_answer(search_prompt, rag_method):\n",
    "    if rag_method == \"Vector-Search\":\n",
    "        context = get_context_vector_search(search_prompt)\n",
    "        theprompt = generate_prompt_vector_search(search_prompt, context)\n",
    "    else: \n",
    "    # rag_method == \"GraphRAG\"\n",
    "        context, definitions = get_context_graphrag(search_prompt)\n",
    "        theprompt = generate_prompt_graphrag(search_prompt, context, definitions)\n",
    "    messages = llm(theprompt.to_messages())\n",
    "    return messages.content\n",
    "\n",
    "def bot(history, rag_method):\n",
    "    bot_message = get_answer(history[-1][0], rag_method)\n",
    "    history[-1][1] = \"\"\n",
    "    for character in bot_message:\n",
    "        history[-1][1] += character\n",
    "        time.sleep(0.01)\n",
    "        yield history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"Chatbot with RAG\", \n",
    "        avatar_images=[\"https://png.pngtree.com/png-vector/20220525/ourmid/pngtree-concept-of-facial-animal-avatar-chatbot-dog-chat-machine-illustration-vector-png-image_46652864.jpg\",\"https://d-cb.jc-cdn.com/sites/crackberry.com/files/styles/larger/public/article_images/2023/08/openai-logo.jpg\"]\n",
    "    )\n",
    "    msg = gr.Textbox(label=\"Message\")\n",
    "    rag_method = gr.Radio([\"Vector-Search\", \"GraphRAG\"], label=\"RAG-method:\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, [chatbot, rag_method], chatbot\n",
    "    )\n",
    "    \n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "    \n",
    "demo.queue()\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have the light-mode for the chatbot paste the following after the URL: /?__theme=light"
   ]
  }
 ],
 "metadata": {
  "createdOn": 1712323594898,
  "creator": "admin",
  "customFields": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "modifiedBy": "admin",
  "tags": [],
  "versionNumber": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
